{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mJtPn4UQZ4h8"
   },
   "source": [
    "## 1. Introduction & Objective\n",
    "\n",
    "The goal of this project is to build a Grammar Scoring Engine that evaluates grammar proficiency from spoken audio samples.\n",
    "Each audio is 45-60 seconds long and labeled with a Grammar Score (0 to 5) based on MOS Likert Scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "3TErXbGPZ3JO"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msns\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import librosa\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from scipy.stats import pearsonr\n",
    "import language_tool_python\n",
    "import whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mvQGAwvzaY2p"
   },
   "source": [
    "## 2. Dataset Overview\n",
    "Load the dataset to colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "thzdl7JfalpD"
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"train.csv\")\n",
    "test_df = pd.read_csv(\"test.csv\")\n",
    "\n",
    "print(\"Train shape:\", train_df.shape)\n",
    "print(train_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W27MnUBlaveB"
   },
   "source": [
    "### Audio Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_-rTcY7Xaxdp"
   },
   "outputs": [],
   "source": [
    "def load_audio(path, sr=16000):\n",
    "    y, _ = librosa.load(path, sr=sr)\n",
    "    return y\n",
    "\n",
    "# Example load\n",
    "audio_path = os.path.join(\"train\", train_df[\"file_name\"].iloc[0])\n",
    "audio_data = load_audio(audio_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TXMhePWIa2m1"
   },
   "source": [
    "### Transcription (Whisper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DYMigJLWa5c2"
   },
   "outputs": [],
   "source": [
    "whisper_model = whisper.load_model(\"base\")\n",
    "\n",
    "def transcribe_audio(path):\n",
    "    result = whisper_model.transcribe(path)\n",
    "    return result['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lsi8sqM6a8nV"
   },
   "source": [
    "###Grammar Error Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dAN95_vZa-j3"
   },
   "outputs": [],
   "source": [
    "tool = language_tool_python.LanguageTool('en-US')\n",
    "\n",
    "def grammar_error_count(text):\n",
    "    matches = tool.check(text)\n",
    "    return len(matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nqk3OY_MbALQ"
   },
   "source": [
    "### Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GxT4MzZYbFQJ"
   },
   "outputs": [],
   "source": [
    "def extract_features(audio_path):\n",
    "    transcript = transcribe_audio(audio_path)\n",
    "    num_errors = grammar_error_count(transcript)\n",
    "    audio, _ = librosa.load(audio_path, sr=16000)\n",
    "    mfcc = librosa.feature.mfcc(audio, sr=16000, n_mfcc=13)\n",
    "    mfcc_mean = mfcc.mean(axis=1)\n",
    "    features = list(mfcc_mean) + [num_errors]\n",
    "    return features\n",
    "\n",
    "# Example\n",
    "sample_features = extract_features(audio_path)\n",
    "print(\"Feature vector length:\", len(sample_features))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hb7GUgJwbIER"
   },
   "source": [
    "# Prepare Dataset for Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WTA5Y6EVbLcP"
   },
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "for idx, row in train_df.iterrows():\n",
    "    audio_path = os.path.join(\"train\", row[\"file_name\"])\n",
    "    features = extract_features(audio_path)\n",
    "    X.append(features)\n",
    "    y.append(row[\"label\"])\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GyOlwXHYbNL_"
   },
   "source": [
    "### Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gkBU799BbQX5"
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5ZgEPePGbSyI"
   },
   "source": [
    "## TRAIN MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h-fR6DdpbUaZ"
   },
   "outputs": [],
   "source": [
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cw2rYVUybU9J"
   },
   "source": [
    "##Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GPbDEV_ibXo3"
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_val)\n",
    "\n",
    "mse = mean_squared_error(y_val, y_pred)\n",
    "mae = mean_absolute_error(y_val, y_pred)\n",
    "pearson_corr, _ = pearsonr(y_val, y_pred)\n",
    "\n",
    "print(\"MSE:\", mse)\n",
    "print(\"MAE:\", mae)\n",
    "print(\"Pearson Correlation:\", pearson_corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YwCM_ViIbZjh"
   },
   "source": [
    "Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PqRV5K0kbbjT"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "sns.scatterplot(x=y_val, y=y_pred)\n",
    "plt.xlabel(\"Actual Scores\")\n",
    "plt.ylabel(\"Predicted Scores\")\n",
    "plt.title(\"Predicted vs Actual Grammar Scores\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k4mShNn6bc8H"
   },
   "source": [
    "#Predict on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hNvb4meHcDrD"
   },
   "outputs": [],
   "source": [
    "submission = pd.read_csv(\"sample_submission.csv\")\n",
    "\n",
    "predictions = []\n",
    "for filename in test_df[\"file_name\"]:\n",
    "    audio_path = os.path.join(\"test\", filename)\n",
    "    features = extract_features(audio_path)\n",
    "    pred = model.predict([features])[0]\n",
    "    predictions.append(pred)\n",
    "\n",
    "submission[\"label\"] = predictions\n",
    "submission.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QYpW6YgIcFgx"
   },
   "source": [
    "# ============================\n",
    "# 14. Conclusion\n",
    "# ============================\n",
    "\n",
    "\"\"\"\n",
    "In this notebook, we built a baseline Grammar Scoring Engine using audio and linguistic features.\n",
    "Future improvements may include deep learning models (e.g., BERT + CNN) and data augmentation.\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
